# Bayesian-RNN-DA-Classifier


##Overview
An LSTM for Dialogue Act (DA) classification on the Switchboard Dialogue Act Corpus.
The repository contains two LSTM models implemented in [Keras](https://keras.io/).
da_lstm.py uses utterance representations generated from traditional word embedding 
and bayes_lstm.py uses utterance representations generated from keywords selected for their frequency association with
certain DAs. 

Both models use the same architecture, with the ouput of the LSTM at each timestep combined using a max-pooling layer
before a final feed forward layer outputs the probability distribution over all DA labels for that utterance.

![rnn architecture](https://github.com/NathanDuran/Bayesian-RNN-DA-Classifier/models/architecture_diagram.png)


##Datasets
The data directory contains pre-processed Switchboard DA Corpus data in raw-text (.txt) and .pkl format.
The same training and test splits as used by [Stolcke et al.(2000)](https://web.stanford.edu/~jurafsky/ws97) and an additional validation set is included.
The development set is a subset of the training set to speed up development and testing. metadata.pkl contains
useful pre-processed data such as vocabulary and vocabulary size, DA label to index conversion dictionary and maximum utterance length.


|Dataset    |# Transcripts  |# Utterances   |
|-----------|:-------------:|:-------------:|
|Training   |1115           |192,768        |
|Development|300            |51,611         |
|Test       |19             |4,088          |
|Validation |21             |3,196          |


##Usage
####Traditional Word Embeddings
To run da_lstm.py an embedding matrix must first be created from pre-trained embeddings such as word2vec or GloVe.
To generate the matrix simply run generate_embeddings.py after specifying the embeddings filename and directory (default = 'embeddings').
Then run da_lstm.py after specifying the name of the .pkl embeddings file generated by generate_embeddings.py.

####Bayesian Word Embeddings
To run bayes_lstm.py a probability matrix must first be created from the raw swiitchboard data.
Run generate_word_frequencies.py specifying the frequency threshold (freq_thresh) i.e. how many times a word may appear in the corpus to be considered (default = 2).
Then run bayes_lstm.py specifying the same word frequency (word_frequency) parameter.

####Utility Files
- process_all_swbd_data.py - processes the entire corpus into raw-text and generates the metadata.pkl file.
- process_batch_swbd_data.py - processes only a specified list of transcripts from a text file i.e. test_split.txt.
- utilities.py - contains utility functions for saving and loading data and models as well as processing data for use at runtime.
- swda.py - contains utility functions for loading and iterating the switchboard transcripts and utterances in .csv format.
This file is part of the repository developed by Christopher Potts, and is available [here](https://github.com/cgpotts/swda).
